{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline: Imagen Diffusion (MRI → SPECT)\n",
        "\n",
        "Entrenamiento de un modelo de difusión directo en espacio de imagen (no latente) usando las mismas carpetas de datos (`whole_MRI`, `whole_SPECT`, `data_info`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "826785da",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "import nibabel as nib\n",
        "\n",
        "from dataset import resolve_nifti, nifti_to_numpy, min_max_norm, z_score_norm, crop\n",
        "from model import UNet\n",
        "import config\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def seed_all(seed: int = 42):\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_all(config.seed)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg = {\n",
        "    'train_txt': config.train,\n",
        "    'val_txt': config.validation,\n",
        "    'test_txt': config.test,\n",
        "    'root_mri': config.whole_MRI,\n",
        "    'root_spect': config.whole_Abeta,\n",
        "    'batch_size': 4,\n",
        "    'num_workers': 0,\n",
        "    'epochs': 200,\n",
        "    'lr': 2e-4,\n",
        "    'time_dim': config.time_dim,\n",
        "    'image_size': 160,  # después se reduce con convs en el UNet cond branch\n",
        "    'save_dir': 'result/exp_image_diffusion/',\n",
        "    'patience': 20,\n",
        "}\n",
        "os.makedirs(cfg['save_dir'], exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset (imagen completa)\n",
        "- MRI: crop a 160×192×160 y z-score.\n",
        "- SPECT: crop y min-max.\n",
        "- Etiquetas desde `data_info.csv` (si falta, usa 0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImagePairDataset(Dataset):\n",
        "    def __init__(self, ids_txt, root_mri, root_spect, stage='train'):\n",
        "        self.ids = [i.strip() for i in open(ids_txt) if i.strip()]\n",
        "        self.root_mri = root_mri\n",
        "        self.root_spect = root_spect\n",
        "        self.stage = stage\n",
        "        self.labels = pd.read_csv('data_info/data_info.csv', encoding='ISO-8859-1')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        bid = self.ids[idx % len(self.ids)]\n",
        "        mri_path = resolve_nifti(self.root_mri, bid)\n",
        "        spect_path = resolve_nifti(self.root_spect, bid)\n",
        "\n",
        "        mri = crop(z_score_norm(nifti_to_numpy(mri_path)))\n",
        "        spect = crop(min_max_norm(nifti_to_numpy(spect_path)))\n",
        "\n",
        "        mri = torch.tensor(mri[None, ...], dtype=torch.float32)\n",
        "        spect = torch.tensor(spect[None, ...], dtype=torch.float32)\n",
        "\n",
        "        label = self.labels[self.labels['ID'].astype(str) == bid]['label'].values.astype(np.float32)\n",
        "        if label.size == 0:\n",
        "            label = np.array([0], dtype=np.float32)\n",
        "        label = torch.tensor(label, dtype=torch.float32)\n",
        "        return mri, spect, bid, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Difusión y modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "125335be",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Diffusion:\n",
        "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=2e-2, device=device):\n",
        "        self.device = device\n",
        "        self.noise_steps = noise_steps\n",
        "        self.beta = torch.linspace(beta_start, beta_end, noise_steps, device=self.device)\n",
        "        self.alpha = 1. - self.beta\n",
        "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
        "\n",
        "    def noise_images(self, x, t):\n",
        "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None, None]\n",
        "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None, None]\n",
        "        eps = torch.randn_like(x)\n",
        "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * eps, eps\n",
        "\n",
        "    def sample_timesteps(self, n):\n",
        "        return torch.randint(1, self.noise_steps, (n,), device=self.device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, model, y, labels=None):\n",
        "        model.eval()\n",
        "        n = y.shape[0]\n",
        "        x = torch.randn((n, 1, 40, 48, 40), device=y.device)\n",
        "        for i in tqdm(reversed(range(1, self.noise_steps)), total=self.noise_steps-1, leave=False):\n",
        "            t = torch.full((n,), i, device=y.device, dtype=torch.long)\n",
        "            pred = model(x, y, t, labels)\n",
        "            alpha = self.alpha[t][:, None, None, None, None]\n",
        "            alpha_hat = self.alpha_hat[t][:, None, None, None, None]\n",
        "            beta = self.beta[t][:, None, None, None, None]\n",
        "            noise = torch.randn_like(x) if i > 1 else torch.zeros_like(x)\n",
        "            x = (1 / torch.sqrt(alpha)) * (x - (1 - alpha) / torch.sqrt(1 - alpha_hat) * pred) + torch.sqrt(beta) * noise\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = ImagePairDataset(cfg['train_txt'], cfg['root_mri'], cfg['root_spect'], stage='train')\n",
        "val_ds = ImagePairDataset(cfg['val_txt'], cfg['root_mri'], cfg['root_spect'], stage='val')\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=cfg['batch_size'], shuffle=True, num_workers=cfg['num_workers'], pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=cfg['num_workers'], pin_memory=True)\n",
        "\n",
        "unet = UNet(in_channel=2, out_channel=1, image_size=40).to(device)\n",
        "optimizer = torch.optim.AdamW(unet.parameters(), lr=cfg['lr'])\n",
        "diffusion = Diffusion()\n",
        "ema = copy.deepcopy(unet).eval().requires_grad_(False)\n",
        "\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "best_ssim = -1e9\n",
        "patience = 0\n",
        "\n",
        "for epoch in range(cfg['epochs']):\n",
        "    unet.train()\n",
        "    loop = tqdm(train_loader, leave=False)\n",
        "    epoch_loss = 0\n",
        "    for mri, spect, bid, label in loop:\n",
        "        mri, spect, label = mri.to(device), spect.to(device), label.to(device)\n",
        "        # dentro del loop de train, antes de sample_timesteps:\n",
        "        spect_small = F.interpolate(spect, size=(40, 48, 40), mode='trilinear', align_corners=False)\n",
        "        t = diffusion.sample_timesteps(spect_small.shape[0]).to(device)\n",
        "        x_t, noise = diffusion.noise_images(spect_small, t)\n",
        "        pred_noise = unet(x_t, mri, t, label)\n",
        "        loss = mse(pred_noise, noise)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        for p, q in zip(ema.parameters(), unet.parameters()):\n",
        "            p.data = 0.999 * p.data + 0.001 * q.data\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        loop.set_description(f\"epoch {epoch+1} loss {loss.item():.4f}\")\n",
        "\n",
        "    # Validación\n",
        "    unet.eval()\n",
        "    psnr_sum = 0\n",
        "    ssim_sum = 0\n",
        "    with torch.no_grad():\n",
        "        for mri, spect, bid, label in val_loader:\n",
        "            mri, spect, label = mri.to(device), spect.to(device), label.to(device)\n",
        "            target = F.interpolate(spect, size=(40, 48, 40), mode='trilinear', align_corners=False)\n",
        "            sampled = diffusion.sample(ema, mri, label)\n",
        "            recon = sampled.cpu().numpy().squeeze().astype(np.float32)\n",
        "            target = target.cpu().numpy().squeeze().astype(np.float32)\n",
        "            data_range = max(target.max() - target.min(), 1e-8)\n",
        "            psnr_sum += psnr(target, recon, data_range=data_range)\n",
        "            min_side = min(target.shape)\n",
        "            win = 7 if min_side >= 7 else (min_side if min_side % 2 == 1 else max(min_side-1,1))\n",
        "            ssim_sum += ssim(target, recon, data_range=data_range, win_size=win)\n",
        "    psnr_avg = psnr_sum / len(val_loader)\n",
        "    ssim_avg = ssim_sum / len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}: loss {epoch_loss/len(train_loader):.4f}, PSNR {psnr_avg:.3f}, SSIM {ssim_avg:.4f}\")\n",
        "\n",
        "    if ssim_avg > best_ssim:\n",
        "        best_ssim = ssim_avg\n",
        "        patience = 0\n",
        "        torch.save({\n",
        "            'state_dict': ema.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'epoch': epoch+1,\n",
        "            'psnr': psnr_avg,\n",
        "            'ssim': ssim_avg,\n",
        "        }, os.path.join(cfg['save_dir'], 'unet_image_best.pth'))\n",
        "    else:\n",
        "        patience += 1\n",
        "        if patience >= cfg['patience']:\n",
        "            print(f\"Early stopping en epoch {epoch+1}\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a7c2e76",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
