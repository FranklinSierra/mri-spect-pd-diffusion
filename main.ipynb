{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b5f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f01f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.train_AAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b634448",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72270669",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.train_LDM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88778d55",
   "metadata": {},
   "source": [
    "# **Checking the performance of AAE in the SPECT domain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbbb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nibabel as nib, numpy as np, torch\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import config\n",
    "from model import AAE\n",
    "from utils import load_checkpoint\n",
    "from dataset import center_crop\n",
    "\n",
    "device = torch.device(config.device)\n",
    "out_dir = os.path.join(\"result\", str(config.exp), \"aae_recon_test\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "latent_dir = config.latent_Abeta\n",
    "sample_id = os.listdir(latent_dir)[0]  # o elige uno\n",
    "latent_path = os.path.join(latent_dir, sample_id)\n",
    "\n",
    "lat = nib.load(latent_path).get_fdata().astype(np.float32)\n",
    "x_lat = torch.tensor(lat[None,None,...], device=device)\n",
    "aae = AAE().to(device)\n",
    "opt = torch.optim.Adam(aae.parameters(), lr=config.learning_rate)\n",
    "load_checkpoint(config.CHECKPOINT_AAE, aae, opt, config.learning_rate)\n",
    "aae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    recon = aae.decoder(x_lat)\n",
    "recon = torch.clamp(recon, 0, 1).cpu().numpy().squeeze().astype(np.float32)\n",
    "\n",
    "orig_id = os.path.splitext(sample_id)[0]\n",
    "orig_path = os.path.join(config.whole_Abeta, orig_id + \".nii\")\n",
    "if not os.path.exists(orig_path):\n",
    "    orig_path = orig_path + \"gz\"  # si es .nii.gz\n",
    "orig_img = nib.load(orig_path)\n",
    "orig = center_crop(orig_img.get_fdata().astype(np.float32), config.crop_size)\n",
    "vmin, vmax = orig.min(), orig.max()\n",
    "orig = np.zeros_like(orig) if vmax - vmin < 1e-8 else (orig - vmin)/(vmax - vmin)\n",
    "rng = max(orig.max() - orig.min(), 1e-8)\n",
    "print(\"PSNR\", psnr(orig, recon, data_range=rng), \"SSIM\", ssim(orig, recon, data_range=rng))\n",
    "\n",
    "nib.save(nib.Nifti1Image(recon, orig_img.affine),\n",
    "         os.path.join(out_dir, f\"{orig_id}_decoder_only.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, nibabel as nib, csv, torch\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import config\n",
    "from dataset import resolve_nifti, center_crop  # usa center_crop\n",
    "from model import AAE\n",
    "\n",
    "device = torch.device(config.device)\n",
    "model = AAE().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "ckpt = torch.load(config.CHECKPOINT_AAE, map_location=device)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "ids = [i.strip() for i in open(config.test) if i.strip()]\n",
    "psnr_sum = ssim_sum = 0\n",
    "\n",
    "with open(\"result/exp_1/aae_recon_test.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f); writer.writerow([\"ID\",\"PSNR\",\"SSIM\"])\n",
    "    for bid in ids:\n",
    "        path = resolve_nifti(config.whole_Abeta, bid)\n",
    "        img = nib.load(path)\n",
    "        data = img.get_fdata().astype(np.float32)\n",
    "        data = center_crop(data, config.crop_size)\n",
    "        vmin, vmax = data.min(), data.max()\n",
    "        data = np.zeros_like(data) if vmax - vmin < 1e-8 else (data - vmin)/(vmax - vmin)\n",
    "\n",
    "        x = torch.tensor(data[None,None,...], device=device)\n",
    "        with torch.no_grad():\n",
    "            recon = model(x)\n",
    "        recon = torch.clamp(recon, 0, 1).cpu().numpy().squeeze().astype(np.float32)\n",
    "\n",
    "        # Asegúrate de que coinciden las formas\n",
    "        if recon.shape != data.shape:\n",
    "            print(f\"{bid} shapes mismatch: data {data.shape}, recon {recon.shape}\")\n",
    "            continue\n",
    "\n",
    "        rng = max(data.max() - data.min(), 1e-8)\n",
    "        ps = psnr(data, recon, data_range=rng)\n",
    "        ss = ssim(data, recon, data_range=rng)\n",
    "        writer.writerow([bid, ps, ss])\n",
    "        psnr_sum += ps; ssim_sum += ss\n",
    "\n",
    "print(\"Promedio PSNR\", psnr_sum/len(ids), \"SSIM\", ssim_sum/len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58312aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python aae_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nibabel as nib, numpy as np, torch\n",
    "gen_path = \"/workspace/projects/T1-SPECT-translation/IL-CLDM/data/latent_SPECT\"\n",
    "files = os.listdir(gen_path)\n",
    "\n",
    "for file in files:\n",
    "    #getting the shape of each file\n",
    "    latent = nib.load(os.path.join(gen_path, file)).get_fdata()\n",
    "    if latent.shape != (40, 48, 40):\n",
    "        print(f\"File: {file}, Shape: {latent.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148f37c3",
   "metadata": {},
   "source": [
    "# **Checking the latent MRI representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7167084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nibabel as nib, torch\n",
    "from dataset import resolve_nifti, center_crop, z_score_norm\n",
    "from model import UNet\n",
    "import config\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(config.device)\n",
    "\n",
    "# Carga el UNet con el image_size correcto\n",
    "unet = UNet(in_channel=2, out_channel=1, image_size=config.latent_shape[0]).to(device)\n",
    "unet.eval()\n",
    "\n",
    "ids = [i.strip() for i in open(config.train) if i.strip()][:3]  # prueba con 3 IDs\n",
    "out_dir = \"result/exp_1/mri_latent_cond\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for bid in ids:\n",
    "        mri_path = resolve_nifti(config.whole_MRI, bid)\n",
    "        img = nib.load(mri_path)\n",
    "        mri = img.get_fdata().astype(np.float32)\n",
    "        # mismo preprocesado que en TwoDataset\n",
    "        from dataset import resample_to_shape\n",
    "        mri = resample_to_shape(mri, config.target_shape)\n",
    "        mri = center_crop(mri, config.crop_size)\n",
    "        mri = z_score_norm(mri)\n",
    "\n",
    "        x = torch.tensor(mri[None, None, ...], device=device)\n",
    "        cond_latent = unet.cond(x).cpu().numpy().squeeze()  # esperado: 40x48x40 con config actual\n",
    "\n",
    "        print(bid, \"cond shape\", cond_latent.shape, \"min/max\", cond_latent.min(), cond_latent.max())\n",
    "        nib.save(nib.Nifti1Image(cond_latent, img.affine),\n",
    "                 os.path.join(out_dir, f\"{bid}_mri_cond.nii.gz\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c33c3",
   "metadata": {},
   "source": [
    "# **Checking the data input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19917c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "base_path = \"/workspace/projects/T1-SPECT-translation/IL-CLDM/data/whole_SPECT\"\n",
    "\n",
    "files = os.listdir(base_path)\n",
    "nan_values = []\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith(\".nii\"):\n",
    "        filepath = os.path.join(base_path, file)\n",
    "        img = nib.load(filepath)\n",
    "        data = img.get_fdata()\n",
    "        print(\"dimansions of the file:\", data.shape)\n",
    "        if np.isnan(data).any():\n",
    "            print(f\"El archivo {file} contiene NaNs.\")\n",
    "            #cuantos NaNs hay\n",
    "            num_nans = np.isnan(data).sum()\n",
    "            print(f\"Número de NaNs en el archivo {file}: {num_nans}\")\n",
    "            nan_values.append((file, num_nans))\n",
    "        else:\n",
    "            print(f\"El archivo {file} no contiene NaNs.\")\n",
    "\n",
    "#obtener el file con menos NaNs y el de mas NaNs\n",
    "if nan_values:\n",
    "    nan_values.sort(key=lambda x: x[1])\n",
    "    print(f\"Archivo con menos NaNs: {nan_values[0][0]} con {nan_values[0][1]} NaNs\")\n",
    "    print(f\"Archivo con más NaNs: {nan_values[-1][0]} con {nan_values[-1][1]} NaNs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d64fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"3863.nii\"\n",
    "filepath = os.path.join(base_path, file)\n",
    "img = nib.load(filepath)\n",
    "data = img.get_fdata()\n",
    "print(\"dimansions of the file:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def resolve(root, bid):\n",
    "    for ext in ('.nii', '.nii.gz'):\n",
    "        p = Path(root)/f\"{bid}{ext}\"\n",
    "        if p.exists(): return p\n",
    "    raise FileNotFoundError(bid)\n",
    "\n",
    "def stats(path):\n",
    "    data = nib.load(str(path)).get_fdata()\n",
    "    data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return data.min(), data.max(), data.mean(), data.std()\n",
    "\n",
    "root_abeta = Path('data/whole_SPECT')\n",
    "root_mri = Path('data/whole_MRI')\n",
    "train_ids = Path('data_info/train.txt').read_text().splitlines()[:-10]  # cambia [:3] por más\n",
    "print('IDs', train_ids)\n",
    "for bid in train_ids:\n",
    "    pA = resolve(root_abeta, bid)\n",
    "    pM = resolve(root_mri, bid)\n",
    "    amin, amax, amean, astd = stats(pA)\n",
    "    mmin, mmax, mmean, mstd = stats(pM)\n",
    "    print(f\"{bid} Abeta: min {amin:.4f} max {amax:.4f} mean {amean:.4f} std {astd:.4f}\")\n",
    "    print(f\"{bid} MRI  : min {mmin:.4f} max {mmax:.4f} mean {mmean:.4f} std {mstd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19fec72",
   "metadata": {},
   "source": [
    "# **Checking the PSNR AND SSIM metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from dataset import OneDataset\n",
    "import config\n",
    "\n",
    "ds = OneDataset(root_Abeta=config.whole_Abeta, task=config.validation, stage=\"validation\")\n",
    "for i in range(3):  # primeros 3\n",
    "    vol, name = ds[i]\n",
    "    vol = vol.astype(np.float32)\n",
    "    rng = max(vol.max() - vol.min(), 1e-8)\n",
    "    print(name, \"range\", vol.min(), vol.max(),\n",
    "          \"PSNR self\", psnr(vol, vol, data_range=rng),\n",
    "          \"SSIM self\", ssim(vol, vol, data_range=rng))\n",
    "    # Volumen con ruido para ver caída\n",
    "    noise = np.random.normal(0, 0.01, size=vol.shape).astype(np.float32)\n",
    "    vol_noisy = np.clip(vol + noise, 0, 1)\n",
    "    print(\"  noisy PSNR\", psnr(vol, vol_noisy, data_range=rng),\n",
    "          \"noisy SSIM\", ssim(vol, vol_noisy, data_range=rng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nibabel as nib, numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import config\n",
    "\n",
    "ids = open(config.validation).read().split()\n",
    "for bid in ids[:10]:  # revisa los primeros 10\n",
    "    path = None\n",
    "    for ext in (\".nii\", \".nii.gz\"):\n",
    "        p = os.path.join(config.whole_Abeta, bid + ext)\n",
    "        if os.path.exists(p):\n",
    "            path = p\n",
    "            break\n",
    "    if not path:\n",
    "        print(\"no file for\", bid)\n",
    "        continue\n",
    "    img = nib.load(path).get_fdata().astype(np.float32)\n",
    "    vol = img[10:170, 18:210, 10:170]  # mismo crop\n",
    "    vmin, vmax = vol.min(), vol.max()\n",
    "    vol = np.zeros_like(vol) if vmax - vmin < 1e-8 else (vol - vmin) / (vmax - vmin)\n",
    "    rng = max(vol.max() - vol.min(), 1e-8)\n",
    "    psnr_self = psnr(vol, vol, data_range=rng)\n",
    "    ssim_self = ssim(vol, vol, data_range=rng)\n",
    "    print(bid, \"range\", vol.min(), vol.max(), \"psnr_self\", psnr_self, \"ssim_self\", ssim_self)\n",
    "    if np.isfinite(ssim_self) and ssim_self > 0.9:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4879a7",
   "metadata": {},
   "source": [
    "# **Plotting curves of the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad4a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09917117",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = \"/workspace/projects/T1-SPECT-translation/IL-CLDM/result/exp_1\"\n",
    "file1 = \"loss_curve.csv\"\n",
    "file2 = \"validation.csv\"\n",
    "\n",
    "loss_df = pd.read_csv(os.path.join(gen_path, file1))\n",
    "similarity_df = pd.read_csv(os.path.join(gen_path, file2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3323ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3483cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting loss curve\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_df['Epoch'], loss_df['recon_loss'], label='Reconstruction Loss')\n",
    "plt.plot(loss_df['Epoch'], loss_df['disc_loss_epoch'], label='Discriminator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the similarity metrics\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(similarity_df['Epoch'], similarity_df['SSIM'], label='SSIM')\n",
    "plt.plot(similarity_df['Epoch'], similarity_df['PSNR'], label='PSNR')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Similarity Metrics')\n",
    "plt.title('Validation Similarity Metrics')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acca89c8",
   "metadata": {},
   "source": [
    "# **Converting the nii.gz into nii files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import gzip\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"/workspace/projects/T1-SPECT-translation/IL-CLDM/data/whole_SPECT\"\n",
    "output_folder = \"/workspace/projects/T1-SPECT-translation/IL-CLDM/data/whole_SPECT2\"\n",
    "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for f in Path(input_folder).glob(\"*.nii.gz\"):\n",
    "    img = nib.load(str(f))\n",
    "    out_path = Path(output_folder) / f.with_suffix('').name  # quita .gz → .nii\n",
    "    nib.save(img, str(out_path))\n",
    "    print(\"Guardado:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d1311",
   "metadata": {},
   "source": [
    "# **Testing the trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c08e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python infer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a727ddd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
